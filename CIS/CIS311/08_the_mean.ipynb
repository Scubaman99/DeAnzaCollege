{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdRKyr-btqaJ"
   },
   "source": [
    "# The Mean\n",
    "\n",
    "## Reading\n",
    "\n",
    "[Chapter 14: 14.1 - 14.5](https://inferentialthinking.com/chapters/14/Why_the_Mean_Matters.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFTscaclt5wi"
   },
   "source": [
    "In the previous notebook we saw how we can estimate parameters of the entire population based on statistical analyses of the parameters of a sample. We also saw that there are some conditions where the estimations will likely be accurate, and these conditions depend on some properties of the sample, such as the mean and the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NzfuVu5hw7a5"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ob9KKZxZuwoa"
   },
   "source": [
    "## Properties of the Mean\n",
    "\n",
    "- <u>Calculation of the Mean</u>\n",
    "\n",
    "The _mean_ is also commonly called the average. It is found by summing all the data values in the dataset and divide by the total number of data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "unZJiSHDvNoR",
    "outputId": "dc76f545-cbbb-4cb3-8818-82c981def866"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "array = np.array([12, 3, 23, 4, 15])\n",
    "print(sum(array)/len(array))\n",
    "print(np.mean(array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_N8BOtuwZwY"
   },
   "source": [
    "- <u>When Data is 1 and 0, or True and False</u>\n",
    "\n",
    "When the data sequence contains only 1's and 0's, then:\n",
    "> - The sum is the number of 1's.\n",
    "> - The mean is the proportion of the 1's.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BptdHB15tpN1",
    "outputId": "f655575a-4ef9-42b4-c221-a84311fc37b5"
   },
   "outputs": [],
   "source": [
    "array = np.array([1,0,1,1,1,0])\n",
    "print(\"Count of 1's:\", sum(array))\n",
    "print(\"Proportion of 1's:\", sum(array)/len(array))\n",
    "print(\"The mean:\", np.mean(array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fx88Ah5Eyvqf"
   },
   "source": [
    "For computers, True means 1 and False means 0. Therefore, when the data sequence contains True and False, we can calculate the count of True's and proportion of True's the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ss3ySXWMzEDD",
    "outputId": "267221e8-8207-4402-8972-b3c1141a4867"
   },
   "outputs": [],
   "source": [
    "array = np.array([True, False, True, True, True, False])\n",
    "print(\"Count of True's:\", sum(array))\n",
    "print(\"Proportion of True's:\", sum(array)/len(array))\n",
    "print(\"The mean:\", np.mean(array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdPVL_TR07ES"
   },
   "source": [
    "- <u>The Mean and the Histogram</u>\n",
    "\n",
    "The mean value depends on each unique data value and its proportion in the dataset.\n",
    "\n",
    "In the following `array1`, the unique data values are 1, 2, 6, and each value's proportion is dependent on how many times it appears in the sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LbwKWDMf15Hv",
    "outputId": "fc563f3f-4e39-4860-c91a-366e6a8cb242"
   },
   "outputs": [],
   "source": [
    "array1 = np.array([1,2,2,6])\n",
    "print(\"The mean:\", 1*1/4 + 2*2/4 + 6*1/4)\n",
    "print(\"The mean:\", np.mean(array1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtOEJEHb2ycp"
   },
   "source": [
    "In the following `array2`, the unique data values are also 1, 2, 6, and each value's proportion is the same as in `array1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fydf1Vsg2__L",
    "outputId": "8d215fcc-5602-4708-a923-107da5204c2a"
   },
   "outputs": [],
   "source": [
    "array2 = np.array([1,1,2,2,2,2,6,6])\n",
    "print(\"The mean:\", 1*2/8 + 2*4/8 + 6*2/8)\n",
    "print(\"The mean:\", np.mean(array2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKhXtEJT3KJN"
   },
   "source": [
    "This means _if two arrays have the same distribution_ (same proportion for each unique data value), _then they have the same mean_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Gya9O8V3jsz"
   },
   "source": [
    "If we plot the distribution of `array1`, which is the same as the distribution of `array2`, we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "CGUZQcZz1jDw",
    "outputId": "06572393-4925-4754-87c6-af091250e93e"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.hist(array2, bins=np.arange(1,7), density=True, edgecolor='black', alpha=0.5)\n",
    "plt.hist(array1, bins=np.arange(1,7), density=True, edgecolor='black', alpha=0.5)\n",
    "plt.title(\"Distribution of array1 and array2\")\n",
    "plt.xlabel(\"Value\")\n",
    "\n",
    "# You don't need to write the following code.\n",
    "# The code draws a triangle at the mean.\n",
    "triangle_x = [2.75 - 0.1, 2.75 + 0.1, 2.75]\n",
    "triangle_y = [-0.03,-0.03, 0]\n",
    "plt.fill(triangle_x, triangle_y, color='black', zorder=3)\n",
    "plt.ylim(bottom=-0.04)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6tEFEOH451b"
   },
   "source": [
    "It looks like only one distribution was plotted, but actually both `array1` and `array2` distributions were plotted. Since they're the same distribution, the two histograms overlap each other perfectly. You can turn one of the `plt.hist()` lines of code into a comment so it doesn't run, and you'll see that the plot above is made of a blue histogram and an orange histogram that overlap each other.\n",
    "\n",
    "For the histogram above, imagine that the x-axis is a straight board or a plank, and the 3 bars rest on top of the plank. As shown, the plank is balanced on a fulcrum, which is the black triangle.\n",
    "> - If the fulcrum is in the middle of the plank, which is at 3.5, the plank will tilt left because there's more \"weight\" on the left side.\n",
    "> - If the fulcrum is at 1.5, then the plank will tilt right.\n",
    "> - If the fulcrum is at 2.75 as shown, which is where the mean is, then the plank will be balanced.\n",
    "\n",
    "_The mean is the balance point of the histogram_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVm6uNmE7alO"
   },
   "source": [
    "- <u>The Mean and the Median</u>\n",
    "\n",
    "Recall that the median is the midpoint of the sorted data values. _If a distribution is  symmetrical, then the mean and the median are the same_.\n",
    "\n",
    "Below we create a symmetrical distribution, where the left and right side are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nkC7ySHy_pYr",
    "outputId": "c0e12e43-7905-4108-b403-c1095e4dd286"
   },
   "outputs": [],
   "source": [
    "array = np.array([1,2,2,3,3,3,4,4,5])\n",
    "print(\"The mean:\", np.mean(array))\n",
    "print(\"The median:\", np.median(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "6gZtCUm0_2O0",
    "outputId": "ed9b8c81-46bf-497f-a492-62f030e52632"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.hist(array, bins=np.arange(1,7), density=True, edgecolor='black', alpha=0.5)\n",
    "plt.title(\"Distribution of a Symmetrical Array\")\n",
    "plt.grid()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Wc91rGSAytg"
   },
   "source": [
    "_When the distribution is not symmetric_, or is _skewed_, so that one side extends farther than the other side (also called having a tail), _then the mean is pulled away from the median towards the tail_.\n",
    "\n",
    "Below we create an array with a right hand tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cFEPDT__BYTD",
    "outputId": "7fc33f04-6ba2-4788-8a60-691317b8a336"
   },
   "outputs": [],
   "source": [
    "array = np.array([1,2,2,3,3,3,4,4,4,4,5,5,6,6,7,8,12,15,16,20])\n",
    "print(\"The mean:\", np.mean(array))\n",
    "print(\"The median:\", np.median(array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "YLQhpZd7CB-Q",
    "outputId": "bb57b23d-6120-4186-a79a-ede1fcb09141"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.hist(array, bins=np.arange(1,22), density=True, edgecolor='black')\n",
    "plt.title(\"Distribution of Skewed Array\")\n",
    "plt.scatter(np.mean(array), 0, color='red', s=40, zorder=2)\n",
    "plt.scatter(np.median(array), 0, color='yellow', s=40, zorder=2)\n",
    "plt.grid()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6_wIPi0GC7VE"
   },
   "source": [
    "The histogram is skewed right and has a right hand tail, therefore the red mean is on the right of the yellow median.\n",
    "\n",
    "The mean is affected by the tail: the farther the tail stretches to the right, the more the mean moves to the right or the larger the mean becomes. But the median is not affected by values at the extremes of the distribution, such as the right most values of the tail.\n",
    "\n",
    "This is why for skewed distributions that have a long tail, it is better to look at the median than the mean. In the distribution above, the majority of the data values are around 2-6, and the median of 4.5 describes the data better than the mean of 6.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZCjM4JyWG4dU"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYmd3lH9Jpqg"
   },
   "source": [
    "## Deviation from the Mean\n",
    "\n",
    "We've found that the mean is the balance point of the histogram, and that data spread out from the mean on both the left and right sides of the mean. In this section we will measure the spread of the data.\n",
    "\n",
    "The spread of the data is the average of the distances between all the data points and the mean. To find the spread, we take the following steps:\n",
    "\n",
    "1. Find the _deviation_.\n",
    "\n",
    "We find the distance between the mean and each data point. This is called the deviation from the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mB6PUyLL4Tbs",
    "outputId": "c4396909-3274-448c-b8f9-a81ecc8c9aa6"
   },
   "outputs": [],
   "source": [
    "# create an array of 4 numbers\n",
    "array = np.array([12, 5, 9, 3])\n",
    "# find the mean\n",
    "the_mean = np.mean(array)\n",
    "print(\"The mean:\", the_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kJ1vhPdG4oEF",
    "outputId": "356b2746-1a03-493c-f77c-b20c202d77b0"
   },
   "outputs": [],
   "source": [
    "# find the deviations\n",
    "deviations = array - np.mean(array)\n",
    "# recall that the code above subtracts the mean from\n",
    "# each value in array, creating an array of differences\n",
    "\n",
    "print(\"The deviations:\", deviations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35eWjen559ZB"
   },
   "source": [
    "Note that if we add up all the deviations we would get 0 as the result. This makes sense because the mean is the balance point for the histogram. The sum of distances on the left of the mean should be equal to the sum of distances on the right of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tdqrr_4y6Esc",
    "outputId": "c9870cf8-f9c6-4bc2-8c2a-6804a89535f5"
   },
   "outputs": [],
   "source": [
    "print(sum(deviations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_DU6_ZS5ZxJ"
   },
   "source": [
    "2. Find the _variance_.\n",
    "\n",
    "We square the deviations and take their average.<br>\n",
    "We need to square the deviations for 2 reasons:\n",
    "> - We want to remove the negative signs, otherwise when we add the deviations as a step of finding the average, we would get 0.\n",
    "> - Squaring will put more emphasis on the larger deviations so they count more. For example, $2^2$ is 4, and $8^2$ is 64. The 64 will influence the average more than the 4.\n",
    "\n",
    "Then we average the squares to get the variance. The variance is the mean of the squared deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p5Rs1T8t9-Ib",
    "outputId": "eeeeebe0-6bdd-4c75-f631-b35f8bc6bdea"
   },
   "outputs": [],
   "source": [
    "variance = np.mean(deviations**2)\n",
    "# the code above squares each deviation\n",
    "# and finds the mean of the squares\n",
    "\n",
    "print(\"The variance:\", variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dgE4VpB-UP4"
   },
   "source": [
    "3. Find the _standard deviation_.\n",
    "\n",
    "Since we need to square the deviations in order to find the variance, we now take the square root to \"undo\" the squaring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQ8AyoE8-vkT",
    "outputId": "4ce13a74-03cf-4329-fed3-a36f171676fe"
   },
   "outputs": [],
   "source": [
    "sd = np.sqrt(variance)\n",
    "print(\"The standard deviation:\", round(sd, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DvZR04i6Aun9"
   },
   "source": [
    "Lucky for us, numpy also has the `std()` function to calculate the standard deviation of an array, so we don't have to go through all 3 steps above when we want to find the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kC8KdzDVA20t",
    "outputId": "4366f085-da1c-4691-807d-fc519e919e51"
   },
   "outputs": [],
   "source": [
    "print(\"The standard deviation:\", round(np.std(array), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bK74Sbu5kVZc"
   },
   "source": [
    "When the standard deviation is large compared to the data range, we say that the distribution has a large spread. When the standard devision is small compared to the data range, we say the spread is small.\n",
    "\n",
    "In the example above the data values are from 3 to 12, which means the range is 9. Since the standard deviation is 3.49, we can say that the data has a large spread (3.49/9 is about 0.39 or 39%). A small spread is around 10% or below, and a large spread is around 40% and above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OCwxsLCEzgiM"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zv5Km3TTA-65"
   },
   "source": [
    "## The Standard Deviation\n",
    "\n",
    "<u>Example of Using the Standard Deviation</u>\n",
    "\n",
    "We will use the dataset of basketball players and their heights to work with the <u>s</u>tandard <u>d</u>eviation, or SD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "LmJw3Fe-Bg9D",
    "outputId": "6518bb1e-1bee-4805-cd7b-34a2d5f88b73"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/DeAnzaDataScience/CIS11/refs/heads/main/datasets_notes/nba2013.csv\"\n",
    "nba = pd.read_csv(url)\n",
    "print(\"First 5 rows:\")\n",
    "nba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BdW3pEdCR6e"
   },
   "source": [
    "We now find the mean and standard deviation SD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eirdu5XaCI9g",
    "outputId": "8e147874-fdac-4211-c4c0-30099a51e4f5"
   },
   "outputs": [],
   "source": [
    "mean_height = np.mean(nba[\"Height\"])\n",
    "sd_height = np.std(nba[\"Height\"])\n",
    "print(\"Mean height:\", round(mean_height,2))\n",
    "print(\"Standard deviation:\", round(sd_height,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUyJa7mPkM71"
   },
   "source": [
    "Then we analyze the players' height and compare it against the SD.\n",
    "\n",
    "Below we look at the tallest player's height and the SD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "3N_bsWvUmLMI",
    "outputId": "2cdaafa4-2878-45e8-b9d6-51545f303ea0"
   },
   "outputs": [],
   "source": [
    "tallest_height = nba[\"Height\"].max()\n",
    "tallest_row = nba[nba[\"Height\"] == tallest_height]\n",
    "print(\"Row of tallest player:\")\n",
    "display(tallest_row)\n",
    "print(\"Number of standard deviations:\")\n",
    "print(round((tallest_height - mean_height)/sd_height,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGOOzBFso9UL"
   },
   "source": [
    "The tallest player, Hasheem Thabeet, is more than 2 standard deviations from the mean height."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "33I7V6EmpR8W"
   },
   "source": [
    "Can you write code to find the shortest player and how many standard deviations his height is from the mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TJV24iVMpazO"
   },
   "outputs": [],
   "source": [
    "shortest_height =\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DsZyWbbKoH4H"
   },
   "source": [
    "In general, the majority of data in a dataset are within 2 - 3 standard deviations (SDs) from the mean.\n",
    "\n",
    "The [textbook](https://inferentialthinking.com/chapters/14/2/Variability.html#chebychev-s-bounds) discussed that the mathematician Pafnuty Chebychev proved in a theorem that:\n",
    "- at least 75% of the data is within 2 SDs\n",
    "- at least 89% of the data is within 3 SDs\n",
    "- at least 95% of the data is within 4.5 SDs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktymuxccU5Fm"
   },
   "source": [
    "We can visually see Chebyshev's theorem by plotting the distribution of the players' heights and the lines of 2 SDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "WSO0VB8JT8A0",
    "outputId": "30a886ff-636e-406e-d051-ba0edb1674d8"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.hist(nba[\"Height\"], bins=np.arange(50, 95, 1), density=True, edgecolor='black')\n",
    "plt.axvline(x = mean_height + 2*sd_height, color='red', linestyle='--')\n",
    "plt.axvline(x = mean_height - 2*sd_height, color='red', linestyle='--')\n",
    "plt.title(\"Distribution of Height\")\n",
    "plt.xlabel(\"Height (inches)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46dnVYmDVPSd"
   },
   "source": [
    "The dashed red lines are 2 SDs from the mean, and it does look like at least 75% of the data are within 2 SDs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GeiEmkxU3TZJ"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j4-EhaHcrLyw"
   },
   "source": [
    "### Standard Units\n",
    "\n",
    "The number of units of SD is called the _standard units_ and is named _z_.  We can write a general function to find z."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q6Gb_1FHscAi"
   },
   "outputs": [],
   "source": [
    "def standard_units(array):\n",
    "    return (array - np.mean(array))/np.std(array)\n",
    "\n",
    "# in the function above, the mean is subtracted from each data value,\n",
    "# then the differences are divided by the SD to get the number of SDs,\n",
    "# and the array of number of SDs (z) is returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gle7t4zhm-td"
   },
   "source": [
    "Using the dataset of flight delay times, we check the standard units for the delay times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "BURnwQqbqj-H",
    "outputId": "53a406d3-2a48-4c2a-d169-35dd38ab1f57"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/DeAnzaDataScience/CIS11/refs/heads/main/datasets_notes/united_summer2015.csv\"\n",
    "delays = pd.read_csv(url)\n",
    "print(\"First 5 rows\")\n",
    "delays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yN7OU8PbnTWe"
   },
   "source": [
    "We find the standard units of delay times, using the function we just wrote above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "TUY7fjDPnd7K",
    "outputId": "c826aef1-381e-453c-ef1e-b9f1d16b2b92"
   },
   "outputs": [],
   "source": [
    "delay_su = standard_units(delays[\"Delay\"])\n",
    "print(\"First 5 rows:\")\n",
    "delay_su.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8b0ieg4RLFeX"
   },
   "source": [
    "Then we add the `delay_su` as a new column in the `delays` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "KDb4KhCEoXRa",
    "outputId": "795e5734-3187-4a41-e341-8732954b9c84"
   },
   "outputs": [],
   "source": [
    "delays[\"Delay_SU\"] = delay_su\n",
    "delays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0x9O18XohEY"
   },
   "source": [
    "Next we sort in descending order the DataFrame by the `delay_SU` column so we can see the longest delay times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 380
    },
    "id": "T_mHN0YZowN2",
    "outputId": "aef2f8db-7c26-4b25-dc60-0b526f828814"
   },
   "outputs": [],
   "source": [
    "print(\"First 10 rows of longest delays:\")\n",
    "delays.sort_values(\"Delay_SU\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9NqGwFbpRfJ"
   },
   "source": [
    "We see that there are quite a number of flights that are more than 10 standard units. Since Chebyshev's boundary says that about 90% of the data should be 3 standard units or less, we want to check if Chebyshev's boundary holds true for this dataset.\n",
    "\n",
    "We find the percentage of flights where the standard unit is 3 or less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1B0Fwv-xqfmb",
    "outputId": "0712a9f9-abf3-45de-cd91-11af618de217"
   },
   "outputs": [],
   "source": [
    "percent_flights = len(delays[np.abs(delays[\"Delay_SU\"]) <= 3]) / len(delays)\n",
    "print(round(percent_flights, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KzQ9vUfrLvi"
   },
   "source": [
    "Chebyshev's boundary still holds for the standard units of delay. About 98% of the delays are within 3 standard units, but there are about 2% of flights that have long delays.\n",
    "\n",
    "Looking at the plot for the delays in standard units, we see that the majority of the delays are within 3 SDs, where the red dashed lines are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "Abb9Xt0_1V_5",
    "outputId": "2aecb7da-8fe4-45d5-9edc-0b450b17ca22"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,3))\n",
    "plt.hist(delays.Delay_SU, bins=np.arange(-5, 15, 0.5), density=True, edgecolor='black')\n",
    "plt.title(\"Distribution of Delay SU\")\n",
    "plt.xlabel(\"Delay SU\")\n",
    "plt.axvline(x=np.std(delays['Delay_SU'])*3, color='red', linestyle='--')\n",
    "plt.axvline(x=np.std(delays['Delay_SU'])*-3, color='red', linestyle='--')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWRVBspgrqpO"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "se38FEjloWZr"
   },
   "source": [
    "## The Normal Distribution and Standard Deviation\n",
    "\n",
    "The normal distribution is also known as the Gaussian distribution or the bell curve. It has a symmetric bell-shaped curve, with a peak at the mean value and tapering off equally on both left and right sides. The normal distribution has a special relationship with the standard deviation.\n",
    "\n",
    "We first create a normal distribution and fill in the areas under the normal curve that's within 1 standard deviation and within 2 standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "id": "zPHrH0I15wMM",
    "outputId": "cfc210c2-3647-4c52-9887-8c6c094c0c79"
   },
   "outputs": [],
   "source": [
    "# You don't need to write this code.\n",
    "# The code is to demo the standard deviations of the normal distribution.\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "mean = 0\n",
    "sd = 1\n",
    "\n",
    "# create 1000 x values centered around 0\n",
    "x = np.linspace(mean - 3*sd, mean + 3*sd, 1000)\n",
    "# create y values that form the normal distribution\n",
    "y = norm.pdf(x, mean, sd)\n",
    "\n",
    "# create 2 side-by-side plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 3))\n",
    "\n",
    "# plot normal distribution with filled area within 1 SD\n",
    "axes[0].plot(x, y)\n",
    "x_fill_1 = np.linspace(mean - sd, mean + sd, 1000)\n",
    "y_fill_1 = norm.pdf(x_fill_1, mean, sd)\n",
    "axes[0].fill_between(x_fill_1, y_fill_1, alpha=0.4)\n",
    "axes[0].set_title('Area Under Normal Curve Within 1 SD')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# plot normal distribution with filled area within 2 SD\n",
    "axes[1].plot(x, y)\n",
    "x_fill_2 = np.linspace(mean - 2*sd, mean + 2*sd, 1000)\n",
    "y_fill_2 = norm.pdf(x_fill_2, mean, sd)\n",
    "axes[1].fill_between(x_fill_2, y_fill_2, alpha=0.4)\n",
    "axes[1].set_title('Area Under Normal Curve within 2 SDs')\n",
    "axes[1].grid(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W98CBLZVAr0u"
   },
   "source": [
    "We can see that the area under the curve that's within 2 SDs covers a substantial part of the entire area under the curve.\n",
    "\n",
    "To calculate the area under the curve, we use the `cdf` function of the `norm` module. The `cdf` or _Cumulative Distribution Function_ returns the proportion of\n",
    "$ \\frac{ \\text{area under the curve up to an x value}} { \\text{total area under the curve}} $\n",
    "\n",
    "To call the `cdf` function we use the format:<br>\n",
    "`area_up_to_x = norm.cdf(x)`\n",
    "\n",
    "Using this function, we find proportion of the area under the curve within 1 SD and within 2 SDs compared to the total area under the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_lz8ZX7Z8dVx",
    "outputId": "7311b8c0-b8c4-45b1-fa85-f22998721996"
   },
   "outputs": [],
   "source": [
    "# Area within 1 SD is between -1 and 1\n",
    "print(\"Proportion of area within 1 SD:\", round(norm.cdf(1) - norm.cdf(-1), 3))\n",
    "\n",
    "# Area within 2 SD is between -2 and 2\n",
    "print(\"Proportion of area within 2 SDs:\", round(norm.cdf(2) - norm.cdf(-2), 3))\n",
    "\n",
    "# Area within 3 SD is between -3 and 3\n",
    "print(\"Proportion of area within 3 SDs:\", round(norm.cdf(3) - norm.cdf(-3), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Jmu53ooCGc0"
   },
   "source": [
    "We note that for a normal distribution:\n",
    "- At 2 SDs, the proportion of area under the curve is 95% of the total area, and at 3 SDs, the area under the curve is almost the same as the total area under the curve.\n",
    "- The proportions of area under the curve within 2 SDs and 3 SDs, 95% and 99.7%, are quite a bit higher than Chebyshev's prediction of 75% and 89%. This is because Chebyshev's prediction is for a general distribution, while the area under the curve calculated above is only for the normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izZerh8zFvsU"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZ6SykmWFxGw"
   },
   "source": [
    "## The Central Limit Theorem\n",
    "\n",
    "The _central limit theorem_ says that if we take a large number of random samples from a population and find the mean of each sample, then the distribution of the means will approach a normal distribution, regardless of the original population's distribution.\n",
    "\n",
    "Just like with Chebyshev's bound, we won't go into the mathematical proof of the central limit theorem, instead we will check that it does work with the dataset of flight delays.\n",
    "\n",
    "First we take a look again at the flight delay dataset, which we read in earlier, and the distribution of delay times.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ueuSoywM_8zh",
    "outputId": "d1a10a60-9617-45d5-e67a-4e9e3ff20269"
   },
   "outputs": [],
   "source": [
    "delays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "nvdbMXaeCBsc",
    "outputId": "420b0123-e811-4945-a8fa-cde88d29d7f7"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.hist(delays[\"Delay\"], bins=np.arange(-20, 300, 10), density=True, edgecolor='black')\n",
    "plt.title(\"Distribution of Flight Delay Times\")\n",
    "plt.xlabel(\"Delay Time (min)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fHQjq-0SCa46"
   },
   "source": [
    "The distribution of delay times does not follow a normal curve, it is right-skewed with a long right tail.\n",
    "\n",
    "We also calculate the mean and the SD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Ad86ffLId6W",
    "outputId": "30910907-f4bb-4317-dc61-9becc4523ec6"
   },
   "outputs": [],
   "source": [
    "print(\"The mean:\", round(np.mean(delays[\"Delay\"]),2))\n",
    "print(\"The SD:\", round(np.std(delays[\"Delay\"]),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eLcjviebIwvm"
   },
   "source": [
    "Note that the mean is only about 17 minutes, but the standard deviation is close to 39.5 minutes, a large value due to the small number of data values at the end of the right tail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9M1WMqpH2Ba"
   },
   "source": [
    "Next we take large samples from the delay times and plot the mean of the samples.\n",
    "\n",
    "We write a function to select a sample of 400 values with replacement and find the mean of the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MFLqZ7yLIHxg"
   },
   "outputs": [],
   "source": [
    "def get_sample_mean(num_of_data):\n",
    "    return np.mean(delays[\"Delay\"].sample(num_of_data, replace=True ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kuxoXl3jB5Ns"
   },
   "source": [
    "Then we run the simulation by looping 10,000 times and call `get_sample_mean`, and we plot the means of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AektpCdkLNup"
   },
   "outputs": [],
   "source": [
    "L = []\n",
    "for i in range(10000):\n",
    "    L.append(get_sample_mean(400))\n",
    "mean_array = np.array(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "oXSJMjFvLVWF",
    "outputId": "eaa4f36d-7a3a-4f38-e7ff-68c8345f17fd"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,3))\n",
    "plt.hist(mean_array, bins=np.arange(10, 25, 0.5), edgecolor='black')\n",
    "plt.xlabel('Average Delay')\n",
    "plt.title('Distribution of Average Delays')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieHiKGkjMyf6"
   },
   "source": [
    "We see that the distribution of average delay times is approximately the bell curve or the normal distribution, as predicted by the central limit theorem. We also see that the distribution is centered around the mean, which we calculated above to be 16.66."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8nt0C9nNRQR"
   },
   "source": [
    "We now repeat the same simulation as above, but our sample size is 1,000 instead of 400."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333
    },
    "id": "HtHyyBqcNaAH",
    "outputId": "883d2333-ea9e-411c-ffea-1f185dcdddca"
   },
   "outputs": [],
   "source": [
    "L = []\n",
    "for i in range(10000):\n",
    "    L.append(get_sample_mean(1000))\n",
    "mean_array = np.array(L)\n",
    "\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.hist(mean_array, bins=np.arange(10, 25, 0.5), edgecolor='black')\n",
    "plt.xlabel('Average Delay')\n",
    "plt.title('Distribution of Average Delays')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_wxPGF6N5XE"
   },
   "source": [
    "We notice that once again the distribution of average delay times is a normal distribution that's centered around the mean of 16.6.\n",
    "\n",
    " But we also notice that for samples of 1000 values, the distribution is taller but narrower than the distribution for samples of 400 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEX4OqXNRvd_"
   },
   "source": [
    "Since the 2 distributions above have different spreads and one is narrower than the other, it means they have different standard deviations. The [textbook ](https://inferentialthinking.com/chapters/14/5/Variability_of_the_Sample_Mean.html#the-sd-of-all-the-sample-means) shows that in general, the standard deviation of the means is:\n",
    "\n",
    "$$\n",
    "\\text{SD of all means} = \\frac{ \\text{population SD}}{ \\sqrt{ \\text{sample size}}}\n",
    " $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccHVJ6U6TfPV",
    "outputId": "606f6345-44b4-42c8-bc9f-656541d4f88b"
   },
   "outputs": [],
   "source": [
    "print(\"SD of sample of 400:\", round(np.std(delays[\"Delay\"]) / np.sqrt(400), 2))\n",
    "print(\"SD of sample 1000:\", round(np.std(delays[\"Delay\"]) / np.sqrt(1000),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3s2BkMvUfHH"
   },
   "source": [
    "The SD of the larger sample (1000) is smaller than the SD of the smaller sample (400). A smaller SD means the distribution is narrower and the calculated result is more accurate.\n",
    "\n",
    "In fact, as the equation above shows, the SD of the means decreases (or the accuracy increases) in reverse proportion with $\\sqrt{ \\text{sample size}}$. For the SD to decrease by a factor of 10, the sample size must increase by a factor of 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oK51m2uJQT00"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwpwAnqQaHfT"
   },
   "source": [
    "In this notebook we learn the properties of the mean and the standard deviation of a dataset. We observe that for large samples of a population, the distribution of the mean of the samples is approximately a normal distribution. We also learn from the central limit theorem that the accuracy of a statistic of the samples increases in proportion with the square of the sample size."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
